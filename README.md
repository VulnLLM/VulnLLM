# Built-In Security? LLMsâ€™ Security Awareness in the Software Development Lifecycle

This repository contains the full set of experimental scenarios(prompts) and model outputs for the paper.

## ğŸ“˜ Paper Overview

This study evaluates whether general-purpose LLMs can exhibit spontaneous security awareness during typical software development tasks. Using 78 code snippets across 12 SDLC-inspired scenarios and three prompt strategies, we generate 8,424 model responses and assess the accuracy, false positive rates, and contextual behavior of three leading LLMs (GPT-4o, DeepSeek-V3, and Qwen2.5-Coder).

### ğŸ” Key Research Questions

1. **RQ1**: Can LLMs identify vulnerabilities without explicit prompting?
2. **RQ2**: How do different prompt strategies influence vulnerability detection?
3. **RQ3**: How trustworthy are security alerts on benign code?
